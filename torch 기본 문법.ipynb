{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b45a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ed5016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "=======================\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], device='cuda:0')\n",
      "=======================\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([[1, 2], [3, 4]])) # 2차원 형태의 텐서 생성\n",
    "print('=======================')\n",
    "print(torch.tensor([[1, 2], [3, 4]], device='cuda:0')) # GPU에 텐서 생성\n",
    "print('=======================')\n",
    "print(torch.tensor([[1, 2], [3, 4]], dtype=torch.float64)) # dtype을 이용하여 텐서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86258100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])\n",
    "temp.numpy() # 텐서를 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25370d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]], device='cuda:0')\n",
    "temp.to('cpu').numpy() # gpu상의 텐서를 cpu텐서로 변환한 후 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2395ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.)\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp[0], temp[1]) # 인덱스로 접근\n",
    "print(temp[0:3]) # 슬라이스로 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f77fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "=======================\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "=======================\n",
      "tensor([1, 2, 3, 4])\n",
      "=======================\n",
      "tensor([[1, 2, 3, 4]])\n",
      "=======================\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1, 2], [3, 4]])\n",
    "print(temp.shape)\n",
    "print('=======================')\n",
    "print(temp.view(4, 1)) # 2x2 행렬을 4x1 행렬로 변형\n",
    "print('=======================')\n",
    "print(temp.view(-1)) # 2x2 행렬을 1차원 벡터로 변형\n",
    "print('=======================')\n",
    "print(temp.view(1, -1)) # 2x2 행렬을 1x4 행렬로 변형\n",
    "print('=======================')\n",
    "print(temp.view(-1, 1)) # 2x2 행렬을 4x1 행렬로 변형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self): # 필요한 변수를 선언하고, 데이터셋의 전처리를 해 주는 함수\n",
    "    def __len__(self): # 데이터셋의 길이. 즉, 총 샘플의 수를 가져오는 함수\n",
    "    def __getitem__(self, index): # 데이터셋에서 특정 데이터를 가져오는 함수 (index번째 데이터를 반환하는 함수이며, 이때 반환되는 값은 텐서의 형태를 취해야 함)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0243568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file): # csv_file 파라미터를 통해 데이터셋을 불러온다.\n",
    "        self.label = pd.read_csv(csv_file)\n",
    "        \n",
    "    def __len__(self): # 전체 데이터셋의 크기를 반환한다.\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx): # 전체 x와 y 데이터 중에 해당 idx번째의 데이터를 가져온다.\n",
    "        sample = torch.tensor(self.label.iloc[idx, 0:3]).int()\n",
    "        label = torch.tensor(self.label.iloc[idx, 3]).int()\n",
    "        return sample, label\n",
    "    \n",
    "tensor_dataset = CustomDataset('../covtype.csv') # 데이터셋으로 covtype.csv를 사용한다.\n",
    "dataset = DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataset, 0):\n",
    "    print(i, end='')\n",
    "    batch = data[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a97ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c64a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = Linear(inputs, 1) # 계층 정의\n",
    "        self.activation = Sigmoid() # 활성화 함수 정의\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8517085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing children \n",
      "-------------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "\n",
      "\n",
      "printing Modules\n",
      "-------------------------\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            x = self.layer3(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "model = MLP()\n",
    "\n",
    "print('printing children \\n-------------------------')\n",
    "print(list(model.children()))\n",
    "print('\\n\\nprinting Modules\\n-------------------------')\n",
    "print(list(model.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2943db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, \n",
    "                                              lr_lambda=lambda eopch: 0.95 ** epoch)\n",
    "\n",
    "for eopch in range(1, 100+1): # 에포크 수만큼 데이터를 반복하여 처리\n",
    "    for x, y in dataloader: # 배치 크기만큼 데이터를 가져와서 학습 진행\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "loss_fn(model(x), y).backward()\n",
    "optimizer.step()\n",
    "scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2654c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "metric = torchmetrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584316e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "\n",
    "acc = torchmetrics.functional.accuracy(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d92bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1882, 0.2312, 0.3371, 0.1036, 0.1399],\n",
       "        [0.0739, 0.1607, 0.4228, 0.1842, 0.1583],\n",
       "        [0.3132, 0.0837, 0.2375, 0.0995, 0.2662],\n",
       "        [0.1018, 0.0979, 0.1960, 0.2996, 0.3047],\n",
       "        [0.0502, 0.1793, 0.0452, 0.4686, 0.2567],\n",
       "        [0.0458, 0.8307, 0.0254, 0.0569, 0.0412],\n",
       "        [0.0642, 0.2372, 0.4178, 0.0318, 0.2491],\n",
       "        [0.0609, 0.6555, 0.1093, 0.1172, 0.0572],\n",
       "        [0.0341, 0.3943, 0.2767, 0.0885, 0.2064],\n",
       "        [0.0749, 0.2142, 0.1300, 0.1565, 0.4244]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07153430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 1, 3, 0, 2, 3, 1, 4, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb39dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "metric = torchmetrics.Accuracy()\n",
    "\n",
    "n_batchs = 10\n",
    "for i in range(n_batchs):\n",
    "    preds = torch.randn(10, 5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "    \n",
    "    acc = torchmetrics.functional.accuracy(preds, target)\n",
    "    print(f'accuracy on batch {i}: {acc}') # 현재 배치에서 모델 정확도\n",
    "    \n",
    "acc = metric.compute()\n",
    "print(f'accuracy no all data: {acc}') # 모든 배치에서 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b809bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./') # 모니터링에 필요한 값들이 저장될 위치\n",
    "\n",
    "for eopch in range(num_epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f85fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
